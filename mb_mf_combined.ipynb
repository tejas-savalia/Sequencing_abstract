{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environment = numpy.zeros((2, 7))\n",
    "trans_prob = 0.7\n",
    "environment[1, 6] = 10\n",
    "#environment[8, 8] = -10\n",
    "environment[1, 0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_legal_actions(pos):\n",
    "    legal_actions = list()\n",
    "    new_pos = list()\n",
    "    all_actions = [[1, 0], [0, 1], [-1, 0], [0, -1]]\n",
    "    for i in all_actions:\n",
    "        try:\n",
    "            new_pos = numpy.add(pos, numpy.array(i))\n",
    "            legal_actions.append(i)\n",
    "            env = environment[new_pos[0]][new_pos[1]]\n",
    "            if any(j < 0 for j in new_pos):\n",
    "                legal_actions.pop()\n",
    "        except IndexError:\n",
    "            legal_actions.pop()\n",
    "            \n",
    "        \n",
    "    return legal_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_action(pos, action):\n",
    "    # Take action in the actual environment and return a reward and new position based on environment dynamics\n",
    "    if numpy.random.rand(1) < trans_prob:\n",
    "        new_pos = numpy.add(pos, action)\n",
    "    else:\n",
    "        new_pos = numpy.add(pos, random.choice(get_legal_actions(pos)))\n",
    "    reward = environment[new_pos[0]][new_pos[1]]\n",
    "    return new_pos, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mb_internal_environment_value(pos, mb_internal_environment):\n",
    "    value = mb_internal_environment[pos[0], pos[1]]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_mb_internal_environment(pos, next_pos, reward, mb_internal_environment):\n",
    "    next_value_list = list()\n",
    "    for i in get_legal_actions(next_pos):\n",
    "        next_value_list.append(mb_internal_environment[next_pos[0]][next_pos[1]])\n",
    "    next_value = max(next_value_list)\n",
    "    mb_internal_environment[pos[0], pos[1]] = (1-alpha) * mb_internal_environment_value(pos, mb_internal_environment) + (alpha) * (reward + gamma*next_value) - 0.1\n",
    "    return mb_internal_environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dls(pos, curr_depth, max_depth, mb_internal_environment):\n",
    "    value_list = list()\n",
    "    if curr_depth == max_depth:\n",
    "        return mb_internal_environment_value(pos, mb_internal_environment)\n",
    "    else:\n",
    "        actions = get_legal_actions(pos)\n",
    "        for i in actions:\n",
    "            next_pos = numpy.add(numpy.array(pos), numpy.array(i))\n",
    "            value = mb_internal_environment_value(pos, mb_internal_environment) + gamma * dls(next_pos, curr_depth+1, max_depth, mb_internal_environment)\n",
    "            value_list.append(value)\n",
    "        if value_list:\n",
    "            average_value = numpy.mean(numpy.array(value_list))\n",
    "    return average_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dls_action(pos, max_depth, mb_internal_environment):\n",
    "    # Do depth Limited Search till max_depth on the mb_internal_environment\n",
    "    actions = get_legal_actions(pos)\n",
    "    next_value_list = list()\n",
    "    next_pos_list = list()\n",
    "    for i in actions:\n",
    "        next_pos = numpy.add(numpy.array(pos), numpy.array(i))\n",
    "        next_value_list.append(dls(next_pos, 0, max_depth, mb_internal_environment))\n",
    "        next_pos_list.append(next_pos)\n",
    "    zipped = list(zip(actions, next_value_list))\n",
    "    random.shuffle(zipped)\n",
    "    actions, next_value_list = zip(*zipped)\n",
    "    action = actions[numpy.argmax(next_value_list)]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q_action(pos, mb_internal_environment):\n",
    "    # Look for q values in mf_internal_environment for given position\n",
    "    actions = get_legal_actions(pos)\n",
    "    next_value_list = list()\n",
    "    next_pos_list = list()\n",
    "    for i in actions:\n",
    "        next_pos = numpy.add(numpy.array(pos), numpy.array(i))\n",
    "        next_value_list.append(mb_internal_environment[next_pos[0], next_pos[1]])\n",
    "        next_pos_list.append(next_pos)\n",
    "    zipped = list(zip(actions, next_value_list))\n",
    "    random.shuffle(zipped)\n",
    "    actions, next_value_list = zip(*zipped)\n",
    "    action = actions[numpy.argmax(next_value_list)]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dual(num_iters, mb_internal_environment, change_env, change_at):\n",
    "    sum_reward = 0\n",
    "    max_depth = 3\n",
    "    steps_per_reward = 0\n",
    "    steps = list()\n",
    "    time_per_reward = list()\n",
    "    first_action = list()\n",
    "    response_time_across_trials = list()\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        response_time = list()\n",
    "        pos = [0, 0]\n",
    "        j = 0\n",
    "        goal_start_time = time.time()\n",
    "        #change the environment at moderate training\n",
    "        if change_env and i == change_at:\n",
    "            environment[6, 6] = -10\n",
    "            environment[0, 0] = 10\n",
    "        while True:\n",
    "            if j%(i+1) == 0:\n",
    "                response_time_start = time.time()\n",
    "                action = dls_action(pos, max_depth, mb_internal_environment)\n",
    "                next_pos, reward = take_action(pos, action)\n",
    "                mb_internal_environment = update_mb_internal_environment(pos, next_pos, reward, mb_internal_environment)\n",
    "                pos = next_pos\n",
    "                response_time_end = time.time()\n",
    "                \n",
    "            else:\n",
    "                response_time_start = time.time()\n",
    "                action = q_action(pos, mb_internal_environment)\n",
    "                next_pos, reward = take_action(pos, action)\n",
    "                mb_internal_environment = update_mb_internal_environment(pos, next_pos, reward, mb_internal_environment)\n",
    "                pos = next_pos\n",
    "                response_time_end = time.time()\n",
    "                \n",
    "            response_time.append(response_time_end - response_time_start)\n",
    "            sum_reward = 0.5*sum_reward + 0.5*reward\n",
    "            steps_per_reward += 1\n",
    "            if j == 0:\n",
    "                first_action.append(action)\n",
    "            j += 1\n",
    "            if reward != 0:\n",
    "                mb_internal_environment[pos[0], pos[1]] = (1-alpha) * mb_internal_environment_value(pos, mb_internal_environment) + (alpha) * (reward)\n",
    "                steps.append(steps_per_reward)\n",
    "                steps_per_reward = 0\n",
    "                #print \"here\", pos\n",
    "                goal_time = time.time()\n",
    "                time_per_reward.append(goal_time - goal_start_time)\n",
    "                \n",
    "                break\n",
    "        response_time_across_trials.append(numpy.mean(response_time))\n",
    "    return sum_reward, steps, mb_internal_environment, time_per_reward, first_action, response_time_across_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mb(num_iters, mb_internal_environment):\n",
    "    sum_reward = 0\n",
    "    max_depth = 3\n",
    "    steps = list()\n",
    "    time_per_reward = list()\n",
    "    for i in range(num_iters):\n",
    "        pos = [0, 0]\n",
    "        steps_per_reward = 0\n",
    "        goal_start_time = time.time()\n",
    "        while True:\n",
    "            action = dls_action(pos, max_depth, mb_internal_environment)\n",
    "            next_pos, reward = take_action(pos, action)\n",
    "            mb_internal_environemnt = update_mb_internal_environment(pos, next_pos, reward, mb_internal_environment)\n",
    "            pos = next_pos\n",
    "            sum_reward = 0.5*sum_reward + 0.5*reward\n",
    "            steps_per_reward += 1\n",
    "            if reward != 0:\n",
    "                mb_internal_environment[pos[0], pos[1]] = (1-alpha) * mb_internal_environment_value(pos, mb_internal_environment) + (alpha) * (reward)                \n",
    "                steps.append(steps_per_reward)\n",
    "                steps_per_reward = 0\n",
    "                goal_time = time.time()\n",
    "                time_per_reward.append(goal_time - goal_start_time)\n",
    "                #print \"here\"\n",
    "                break\n",
    "\n",
    "    return sum_reward, steps, mb_internal_environment, time_per_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mf(num_iters, mb_internal_environment):\n",
    "    sum_reward = 0\n",
    "    steps = list()\n",
    "    time_per_reward = list()\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        pos = [0, 0]\n",
    "        steps_per_reward = 0        \n",
    "        #print (mb_internal_environment)\n",
    "        goal_start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            action = q_action(pos, mb_internal_environment)\n",
    "            next_pos, reward = take_action(pos, action)\n",
    "            mb_internal_environment = update_mb_internal_environment(pos, next_pos, reward, mb_internal_environment)\n",
    "            pos = next_pos\n",
    "            sum_reward = 0.5*sum_reward + 0.5*reward\n",
    "            steps_per_reward += 1\n",
    "            if reward != 0:\n",
    "                \n",
    "                mb_internal_environment[pos[0], pos[1]] = (1-alpha) * mb_internal_environment_value(pos, mb_internal_environment) + (alpha) * (reward)\n",
    "                steps.append(steps_per_reward)\n",
    "                steps_per_reward = 0\n",
    "                goal_time = time.time()\n",
    "                time_per_reward.append(goal_time - goal_start_time)\n",
    "                \n",
    "                break\n",
    "            \n",
    "    return sum_reward, steps, mb_internal_environment, mb_internal_environment, time_per_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Dual Process on grid world. Get a list of individual time taken for each and rewards obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times_dual = list()\n",
    "reward_dual = list()\n",
    "steps_dual = list()\n",
    "time_per_reward_dual = list()\n",
    "first_action_dual = list()\n",
    "response_time_dual = list()\n",
    "change_at = 30\n",
    "iterations = 50\n",
    "change = False\n",
    "trials = 10\n",
    "for i in range(trials):\n",
    "    environment = numpy.zeros((10, 10))\n",
    "    trans_prob = 0.7\n",
    "    environment[9, 9] = 10\n",
    "    #environment[8, 8] = -10\n",
    "    #environment[0, 0] = -10\n",
    "    mb_internal_environment = numpy.zeros((10, 10))\n",
    "    #mb_internal_environment[6, 6] = 10\n",
    "    start_time = time.time()\n",
    "    dual_result = dual(iterations, mb_internal_environment, change, change_at)\n",
    "    reward_dual.append(dual_result[0])\n",
    "    steps_dual.append(dual_result[1])\n",
    "    times_dual.append(time.time() - start_time)\n",
    "    time_per_reward_dual.append(dual_result[3])\n",
    "    first_action_dual.append(dual_result[4])\n",
    "    response_time_dual.append(dual_result[5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmUXOV55/HvU0t3VS/VUre6W0JbawMsy4CIUNgMmICH\nsYmXxI7tmNg48SiZY3vAdpw49pwTO8ucnMzE4ziJE+QFHIOJbRJi7DE4xAaExSIEiF0C7QtI3Vp7\n36qe+aNuSy2plyt13a7uqt/nnDpdVV1V97lw9Kvb733v85q7IyIipS9W7AJERGRyKPBFRMqEAl9E\npEwo8EVEyoQCX0SkTCjwRUTKhAJfRKRMKPBFRMqEAl9EpEwkil3AcLNmzfKWlpZilyEiMm08/fTT\nB929Mcxrp1Tgt7S0sHHjxmKXISIybZjZrrCv1ZCOiEiZUOCLiJQJBb6ISJlQ4IuIlAkFvohImVDg\ni4iUCQW+iEiZmPaB7+587eev8cirbcUuRURkSpv2gW9mrF23nUe2KPBFRMYy7QMfIJNK0N47UOwy\nRESmtNII/HSSYz0KfBGRsZRM4Lcr8EVExlQSgV+XTtLeO1jsMkREprSSCPxMSkf4IiLjKY3ATycU\n+CIi4yiJwK9LJ+noGySb82KXIiIyZZVE4GdSSQA6NDVTRGRUkQa+mc0ws3vMbLOZvWJml0WxnUw6\nH/jtPTpxKyIymqiXOPxb4AF3f5+ZVQBVUWykLgh8zcUXERldZIFvZnXAVcDNAO7eD/RHsa1MKr8b\nutpWRGR0UQ7pLALagNvN7Fkz+6aZVUexobqqoSEdBb6IyGiiDPwEcDHwj+6+EugCPn/qi8xsjZlt\nNLONbW1n1wBt6KSthnREREYXZeDvBfa6+5PB43vIfwGcxN3Xuvsqd1/V2Nh4Vhs6ftJWQzoiIqOK\nLPDdfT+wx8zOC576NeDlKLZVXREnHjMd4YuIjCHqWTqfAu4KZuhsBz4WxUbMLN8iWdMyRURGFWng\nu/smYFWU2xiSSSc1pCMiMoaSuNIW8nPxNaQjIjK6kgl8dcwUERlbyQS+euKLiIytZAI/k05oSEdE\nZAylE/ga0hERGVPpBH46Sd9gjt6BbLFLERGZkkoq8EFX24qIjKZkAr9OPfFFRMZUMoE/1CJZJ25F\nREZWOoGvIR0RkTGVTOCfGNJR4IuIjKRkAn+oJ74CX0RkZKUT+OmhZQ510lZEZCQlE/iViTipZEwn\nbUVERlEygQ+62lZEZCwlFfh16okvIjKqkgr8jHrii4iMqrQCX8scioiMqqQCX6teiYiMrqQCX+va\nioiMrqQCvy6dn6Xj7sUuRURkyimpwM+kkuQcOvs0ji8icqrSCnxdbSsiMqpElB9uZjuBDiALDLr7\nqii3N7yB2twZ6Sg3JSIy7UQa+IG3ufvBSdjO8QZqmqkjInK6EhvSUcdMEZHRRB34DvynmT1tZmsi\n3tbxIR0d4YuInC7qIZ0r3X2fmTUBD5rZZndfN/wFwRfBGoAFCxZMaGPHe+LrpK2IyGkiPcJ3933B\nz1bgXmD1CK9Z6+6r3H1VY2PjhLZXm0pgpiEdEZGRRBb4ZlZtZrVD94G3Ay9GtT2AWMyoqUxoSEdE\nZATjBr6ZNZvZt8zs/uDxcjP7vRCf3Qz80syeAzYA/8/dH5hYuePLpNReQURkJGHG8O8Abge+GDx+\nFfg+8K2x3uTu24ELJ1Lc2ci3V9AYvojIqcIM6cxy9x8AOQB3HyR/IdWUlEknNIYvIjKCMIHfZWYN\n5KdYYmaXAscirWoCtOqViMjIwgzpfAa4D1hiZuuBRuB9kVY1AZmUeuKLiIxk3MB392fM7GrgPMCA\nLe4+ZRM1k9ZC5iIiIxk38M0sDrwDaAle/3Yzw92/EnFtZ6UunaSrP8tgNkciXlKdI0REJiTMkM6P\ngV7gBYITt1NZJnWiRXJ9dUWRqxERmTrCBP48d78g8koKZHgDNQW+iMgJYcY87jezt0deSYEc74mv\nmToiIicJc4T/BHCvmcWAAfInbt3dM5FWdpYy6pgpIjKiMIH/FeAy4AWfBquDn1j1SlfbiogMF2ZI\nZw/w4nQIe9CqVyIiowlzhL8deDhontY39ORUnZZ5YiFzBb6IyHBhAn9HcKsIblNaOhknGTddfCUi\ncoowV9p+eTIKKRQzU3sFEZERjBr4ZvZVd7/VzH5M0DhtOHd/V6SVTUAmndQyhyIipxjrCP+7wc//\nMxmFFFImrSN8EZFTjRX4nwJudvdHJquYQsmk1BNfRORUY03LnDbtFE6lnvgiIqcb6wi/ysxWkr+y\n9jTu/kw0JU2cWiSLiJxurMCfC/wNIwe+A9dGUlEBZFL5dW3dHbMRv69ERMrOWIG/1d2nbKiPpS6d\npD+bo28wRyoZL3Y5IiJTQkmuEDJ0ta1m6oiInDBW4P/xpFVRYHXDeuKLiEjeqIHv7v9RiA2YWdzM\nnjWznxTi88JQAzURkdNNxpDOLcArk7Cd4zJaBEVE5DShA9/Mqs70w81sHvBO4Jtn+t6JUE98EZHT\njRv4Zna5mb0MbA4eX2hmXw/5+V8F/ohJXvx8aCFzDemIiJwQ5gj//wL/BTgE4O7PAVeN9yYzuxFo\ndfenx3ndGjPbaGYb29raQpQzvoxO2oqInCbUkI677znlqWyIt10BvMvMdgL/AlxrZneO8Nlr3X2V\nu69qbGwMU864kvEYVRVxjeGLiAwTaolDM7sccDNLmtkfEuIkrLv/ibvPc/cW4IPAL9z9pomVG556\n4ouInCxM4P8B8AnyrRb2ARcFj6e0unRSJ21FRIYJs+LVQeDDE9mIuz8MPDyRzzhTmXRCR/giIsOE\nmaXz12aWCYZzfm5mbWY2aUMzZyuTUotkEZHhwgzpvN3d24EbgZ3AUuBzURZVCOqJLyJysjCBPzTs\n807gh+5+LMJ6CiaTTnKsW4EvIjIkTOD/xMw2A78C/NzMGoHeaMuauEw6SUffILncaeuvi4iUpXED\n390/D1wOrHL3AaALeHfUhU1UJpXAHTr7NVNHRARCzNIJnA+0mNnw1/9zBPUUzNDVtse6B453zxQR\nKWfjBr6ZfRdYAmzixBW2zhQP/Dp1zBQROUmYI/xVwHJ3n1aD4eqJLyJysjAnbV8EZkddSKENLXOo\nq21FRPLCHOHPAl42sw1A39CT7v6uyKoqAA3piIicLEzgfynqIqKgFskiIicL00vnETNrBi4Jntrg\n7q3RljVxNRUJYqbAFxEZEqaXzm8BG4D3A78FPGlm74u6sImKxYxatUgWETkuzJDOF4FLho7qgytt\n/xO4J8rCCiGTTtDeq5O2IiIQbpZO7JQhnEMh31d0+Z74OsIXEYFwR/gPmNnPgLuDxx8AfhpdSYUz\ns6qCts6+8V8oIlIGwvTS+RxwG3BBcFvr7n8cdWGFsKSxhm2tnUyza8ZERCIRtpfOY+TbKuSAp6Ir\np7CWNdfQ1Z/ljWO9nDMjXexyRESKKswsnY+Tn6XzXuB9wBNm9rtRF1YISxtrAHittbPIlYiIFF+Y\nI/zPASvd/RCAmTWQP+L/dpSFFcKy5loAXjvQwdXnNha5GhGR4goz2+YQ0DHscUfw3JRXX11BQ3UF\nW3WELyIS6gh/K/mLrX5Evi3yu4HnzewzAO7+lQjrm7ClTTUa0hERIVzgbwtuQ34U/KwtfDmFt7Sp\nhp88/wbujpkVuxwRkaIJ00vny0P3zSwG1Lh7+3jvM7MUsA6oDLZzj7v/6QRqPSvLmmo41jNAW2cf\nTbWpyd68iMiUEWaWzvfMLGNm1eR7479sZp8L8dl9wLXufiFwEXCDmV06sXLP3NCJ260HNKwjIuUt\nzEnb5cER/XuA+4FFwO+M9ybPG0rZZHCb9CugljVpaqaICIQL/KSZJckH/n3uPkDI4DazuJltAlqB\nB939ybMv9ew01laSSSU0U0dEyl6YwL8N2AlUA+vMbCEw7hg+gLtn3f0iYB6w2sxWnPoaM1tjZhvN\nbGNbW1v4ykMys2CmTsf4LxYRKWFheul8zd3nuvs7gmGaXcDbzmQj7n4UeAi4YYTfrXX3Ve6+qrEx\nmoujljXV6ghfRMpemJO2zWb2LTO7P3i8HPhoiPc1mtmM4H4auB7YPMF6z8qy5hoOdvZzuKu/GJsX\nEZkSwgzp3AH8DDgnePwqcGuI980BHjKz58k3XHvQ3X9yNkVO1NLgxK2O8kWknIUJ/Fnu/gPynTJx\n90HynTPH5O7Pu/tKd7/A3Ve4+59NsNazpsAXEQkX+F1BwzQHCObSH4u0qgI7py5NVUVcJ25FpKyF\naa3wGeA+YImZrQcayS9oPm3EYvmZOjrCF5FyFqa1wjNmdjVwHmDAlmAu/rSytKmGx7ZOiyafIiKR\nCLUYubsPuvtL7v4icI2ZPRhxXQW3rKmW/e29tPdOu+8qEZGCGDXwzexaM3vVzDrN7E4ze4uZbQT+\nCvjHySuxMIZO3G7TsI6IlKmxjvD/BlgDNAD3AI8Dd7j7r7j7v01GcYWknjoiUu7GGsN3d384uP/v\nZrbP3f9+EmqKxPz6KioSMZ24FZGyNVbgzzCz3xj+2uGPp9tRfjxmLGms4bUDmpopIuVprMB/BPj1\nYY/XDXvswLQKfMiP4z+7+0ixyxARKYpRA9/dPzaZhUyGZU01/OT51+nuH6SqIswlCCIipSPUtMxS\nsaypBnfY3tZV7FJERCZdeQV+89BMHY3ji0j5KavAX9hQTSJmvKb1bUWkDIUayDazy4GW4a9393+O\nqKbIJOMxWmZVay6+iJSlcQPfzL4LLAE2caItsgPTLvAhP46/Zb+GdESk/IQ5wl8FLHf3UAuXT3XL\nmmr42Uv76RvMUpmIF7scEZFJE2YM/0VgdtSFTJalzbXkHHYc1EwdESkvYY7wZwEvm9kGoG/oSXd/\nV2RVRWhpYzBT50An58/OFLkaEZHJEybwvxR1EZNpcWM1MVMTNREpP2EWQHlkMgqZLKlknAX1VWqT\nLCJlZ9wxfDO71MyeCvri95tZ1szaJ6O4qCxtqtXFVyJSdsKctP174EPAa0Aa+DjwD1EWFbXlc2rZ\n1tbF60d7il2KiMikCbvE4VYg7u5Zd78duCHasqL1/lXzAbh9/Y4iVyIiMnnCBH63mVUAm8zsr83s\n0yHfN2XNr6/inW+Zw90b9miNWxEpG2GC+3eC130S6ALmA7853pvMbL6ZPWRmL5vZS2Z2y8RKLaw1\nVy2ms2+Q7z25u9iliIhMinED3913AQbMcfcvu/tngiGe8QwCn3X35cClwCfMbPnEyi2cFXPruGJp\nA7ev30H/YK7Y5YiIRC7MLJ1fJ99H54Hg8UVmdt9473P3N9z9meB+B/AKMHdi5RbWmquWcKC9jx9t\n2lfsUkREIhdmSOdLwGrgKIC7bwIWnclGzKwFWAk8OcLv1pjZRjPb2NbWdiYfO2FXLZvF+bNrWbtu\nO7lcSbQKEhEZVZjAH3D3Y6c8FzodzawG+FfgVnc/bf6+u69191XuvqqxsTHsxxaEmfH7Vy/mtdZO\nHn61dVK3LSIy2cIE/ktm9ttA3MyWmdnfAY+F+XAzS5IP+7vcfUouen7jBedwTl2K2x7ZXuxSREQi\nFSbwPwW8mXzjtLuBduDW8d5kZgZ8C3jF3b8ykSKjlIzH+N0rF/HkjsM8t+doscsREYlMmFk63e7+\nRXe/JBh6+aK794b47CvIT+m81sw2Bbd3TLjiCHxw9QJqUwnWrtNRvoiUrlGbp403E2e89sju/kvy\n0zmnvJrKBDddupDbHtnGrkNdLGyoLnZJIiIFN1a3zMuAPeSHcZ5kmoT32frY5S1869EdfPPRHfz5\ne1YUuxwRkYIba0hnNvAFYAXwt8D1wEF3f6TUWiYDNGVSvGflOfzw6T0c6uwb/w0iItPMqIEfNEp7\nwN0/Sv5K2a3Aw2b2yUmrbpKtuWoxvQM5vvvErmKXIiJScGOetDWzSjP7DeBO4BPA14B7J6OwYlja\nVMt1b2riO4/tpKc/W+xyREQKatTAN7N/Bh4HLga+HMzS+XN3L+k+BGuuWsKR7gHueXpPsUsRESmo\nsY7wbwKWAbcAj5lZe3DrmO4rXo3lkpaZrFwwg288uoOs2i2ISAkZaww/5u61wS0z7Fbr7pnJLHIy\nmRm/f9Vidh/u5oEX9xe7HBGRgpnWC5lE5frls1k0q5rb1m3DXUf5IlIaFPgjiMeMj791Ec/vPcYT\n2w8XuxwRkYJQ4I/iNy+eR0N1Bbet21bsUkRECkKBP4pUMs7Nl7fw8JY2Nu8v2XPUIlJGFPhjuOnS\nhaSTcTVVE5GSoMAfw8zqCj5wyXzu2/Q6rx/tKXY5IiITosAfx+9duQgHbl+/o9iliIhMiAJ/HPPr\nq3jnW+bwvSd3c6xnoNjliIicNQV+CGuuWkxXf5ZPf38TvQPqsSMi05MCP4QVc+v4i/es4KEtrdx8\n+wY6+waLXZKIyBlT4Id006UL+eoHLuKpnUf48Dee4EhXf7FLEhE5Iwr8M/Dui+byTzf9Cq/s7+CD\na5+gtT3M0r4iIlODAv8MXb+8mdtvvoQ9R7p5/22Ps+dwd7FLEhEJRYF/Fq5YOos7P/6rHOnq5/3/\n9DjrXm2jb1Anc0VkarOp1A1y1apVvnHjxmKXEdorb7TzkW9voK2jj3QyzqWL63nrskauOncWSxpr\nMCvpdd9FZAows6fdfVWY1yaiLqaUvWlOhof/8Boe33aIR19r49HXDvLQlpcBmFOX4r0r53LLdcuo\nTMSLXKmISISBb2bfBm4EWt19RVTbKbbqygTXLW/muuXNAOw53M0vtx7kF5tb+frD21j3Wht/96GL\nWTSrusiViki5i3IM/w7ghgg/f0qaX1/Fh1Yv4BsfWcU3PrKKvUd6uPFrj3Lvs3uLXZqIlLnIAt/d\n1wFlvXrI9cubuf+Wt/Lmc+r49Pef47M/eI4uXbQlIkWiWToRm1OX5nv/7Ve55deWce+ze/n1v/sl\nL71+rNhliUgZKnrgm9kaM9toZhvb2tqKXU4kEvEYn77+XO76+KV09Q/y3q8/xvee3K31ckVkUhU9\n8N19rbuvcvdVjY2NxS4nUpctaeD+W67i0sUNfOHeF/jsD5+jp1/z90VkchQ98MtNfXUFt998Cbde\nt4x7n93He7++nu1tncUuS0TKQGSBb2Z3A48D55nZXjP7vai2Nd3EY8at153LHR9bzYH2Xt719+v5\n6QtvFLssESlxutK2yPYd7eETdz3Dpj1HufnyFj52RQsL6qt0la6IhHImV9oq8KeA/sEc/+unr3DH\nYzsBmDsjzRVLG7hi6SwuW9JAU22quAWKyJSlwJ+mtrV1sn7rQdZvPcjj2w7R3pufs7+sqYbz52RY\nUJ9mYX01CxqqWFBfxexMilhMfwmIlDMFfgnI5pyXX29n/baDPLH9ENvbuth3tIds7sT/r4p4jKVN\nNVw4v44L5s3gwnkzOLe5hkRc5+JFyoUCv0QNZnO8frSX3Ye72XW4i92Hunn5jXae33vs+ALrqWSM\nN59Tx2WLG/jAJfOZX19V5KpFJEoK/DLj7uw61M1ze4/y/N5jPLfnKM/sPoID157XxE2XLeTqZY0a\n/hEpQQp84fWjPdy9YTd3b9jDwc4+FtRXcdOlC/jNi+fRUFNZ7PJEpEAU+HJc/2COB17az52P72LD\nznwvu3QyTn11BTOrk9RXV1JflWRWTSUXzJ/B6pZ6ZtdpVpDIdKHAlxFt3t/OQ5vbONzVx+GugfzP\n7gGOdPXT2tFL70AOgAX1VaxeVM/qlnpWL6pnYYOuCxCZqrTilYzo/NkZzp+dGfF3g9kcm/d38OSO\nw2zYcYhfbG7lnqfzPfzTyTgLG6pY2FBFS0M1CxuqWdhQxfyZVTTXVWpFL5FpQkf4MiJ3Z1tbJxt2\nHGFbWye7DnWx81A3uw9105/NnfTaWTUVzKlLM6cuxZy6FOfMSDN3Zpp5M6uYNzNNQ3WF/kIQiYiO\n8GXCzIylTbUsbao96flsztnf3suug13sPdrDG0d7eeNYD28c62XnoS4e33aIjlMWeUklY8ydkaap\nNsVgLkfvQI7egSy9g1n6BnIM5pwL5tVxzbmNXH1ek5aDFImIAl/OSDxmzJ2RZu6M9Kivae8dYN+R\nHvYe6WHfkW72BvcPdvZRkYhRm0pSmYiRSsZJJWO4w4Ydh/nSj1+GH7/MwoYqrjm3kWvOa+JNczLM\nqqnQxWQiBaDAl4LLpJJk5iR505yRzxeMZtehLh55tY2Ht7Tx/Y17+M7juwAwg/qqChprK2nKpGiq\nraShuoJMOkkmlQh+JsmkE1RXJoibYWbEY0bcjFgMKhIxGmsqQw8ttfcOkErEqUjoi0ZKh8bwZUrq\nHciycecRdh3uorW9j9aOPto6emnryN8/3NVP32Bu/A8aprYywbmzazlvdi3nNed/Lm6sprW9jy37\nO3j1QAeb93ewZX8H+9t7SSfjrF5Uz+VL8o3sls/J6OI1mXI0LVPKQu9Alo7eQdp7B2jvGaC9d5Cu\nvkFy7mRzjnv+nEPWnZ7+LFtbO9lyIB/oQ60ohqtIxFjaWMP5s2tZ2lzDgWO9rN92iK2t+QVqZlQl\nuWxxA1cum8XV5zYyb2a4thUdvQPUVCYmdOK6dyDLAy/uZ++RblYumMnKBTOoqtAf6KKTtlIm8ucA\n4jTWntmVw+5Oa0cfm/d3sL2tk6baFOfNrqWloWrEcwUH2nt5bNtB1m89xGNbD3L/i/sBWNJYzTXn\nNXH1uY2sXlRPKhmnpz/LC/uO8ezuIzy7+yib9hxlf3svDdUVrJhbx4q5Gd4yt44Vc+uYOyM97pfA\n7kPd3LVhFz/cuJfDXf3Hn0/EjDfPreOShTO5ZFE9F82fQUO1znXI2HSEL3IG8tNV8+caHnm1jSe2\nH6J/MEcqGWNhfTVb2zqPdzRdUF/FygUzWNZUw85D3by47xivtZ74/YyqJEsba1jYUE1LQxULZ+V/\nzp9ZxTO7j3DnE7t4+NU2YmZc/6ZmfueyhayYW8czu4+wcedhntpxhE17j9I/bGgrk0ows7qCGVUV\nzKxKUl9dwYL6KhY31rB4VjWLG6tH/ctgMJvjWM8APQNZsjlnIJv/S2kwl2Mw63T1D9LW0ceB9l4O\ntOd/trb30dU/yFvm1rF6UT2XtNQzb+b4X2RSOBrSEZkkPf1ZnthxiEe2tLHzUBcrzqlj5YIZ+SPu\nEXoW9Q5k2by/gxf2HeOlfcfYcbCLXYe62d/ee9prm2or+dDqBXxo9YJR2130DWZ5Ye8xXnq9ncNd\n/Rzt7udI9wBHuvs52j3Aoc4+3mjvZfg/8zl1KRbNqsYMjnYPcKxngGPdA6dNpx1LOhlndl2KxtpK\nKhMxnttz9Pj6DXPqUqxeVM/FC2YSi1kw3DaQH37ryf+Mx4zqygQ1lXFqKhPB/QSViRix4GR7PHbi\nlojFqKqIB7cEVZX5+4lYjAPtvewdNhts39Ee9h/rZVZNBUubao7fljTWMKOqAsh/uR3s7Gd/e2/w\nxdVLe+8gg9n8EGA2lyObg2wu/2VaVZE4Xmd1ZZzqigTpivxfdF39g3T25YcTO/uydAf/HeNxIxmL\nEY8ZybgRj8UY/geYkf9SNIN0RZwP/+rC0P/9h1Pgi0wzPf1Z9hzpZmfwBTBvZprrljeTLMAQTe9A\nlh0Hu9je1sX2tk62H+xix8Eu4jFjRjpJXTpJXVWSGekK6tIJqioSJOIngjYRNxIxI52M05RJ0Zyp\nPO2cRC7nbDnQwYYdh9mw8zBP7ThMa0ff8d9XxGNk0gkyqSQ1qQTZnB8PyK6+QXoGshPeT4CaygTz\nZqZpzqRo7ehje1vnSSf3Z9XkLwI82NnHWNF3/MvGDMePtx0Jo6oijgEDufxfSMPXsBjNrJpKNv7P\n60JvYzgFvogUlbtzoL2PWCw/TTeVHLv9RjaXHzLqG8iRc2cw5+SGAtOdwazT3T9Id382uOXv9w/m\naM6kmDczzbyZaerSyZO+iLI5Z9+RHra2dbC1tZNtrV0ANNflv7iaa1M0B19idVVJErEYMeO0Ials\nLr/9rr4snX2DdPcP0tOfJZWMU12ZoDaVP/qvSsZPm8mVG7YPuSBvh1J3eP7WppJn9d9aJ21FpKjM\n7Iy6rsZjRiaVhAI3ao3HLL8kaEMV157fPKHPqU0lzyqUYzEjhjHOd96k0Cl9EZEyocAXESkTkQa+\nmd1gZlvMbKuZfT7KbYmIyNgiC3wziwP/APxXYDnwITNbHtX2RERkbFEe4a8Gtrr7dnfvB/4FeHeE\n2xMRkTFEGfhzgT3DHu8NnhMRkSIo+klbM1tjZhvNbGNbW1uxyxERKVlRBv4+YP6wx/OC507i7mvd\nfZW7r2psbIywHBGR8hbZlbZmlgBeBX6NfNA/Bfy2u780xnvagF1nuclZwMGzfO90pv0uL9rv8hJm\nvxe6e6ij5ciutHX3QTP7JPAzIA58e6ywD95z1of4ZrYx7OXFpUT7XV603+Wl0PsdaWsFd/8p8NMo\ntyEiIuEU/aStiIhMjlIK/LXFLqBItN/lRftdXgq631OqPbKIiESnlI7wRURkDNM+8MupQZuZfdvM\nWs3sxWHP1ZvZg2b2WvBzZjFrLDQzm29mD5nZy2b2kpndEjxf6vudMrMNZvZcsN9fDp4v6f0eYmZx\nM3vWzH4SPC6X/d5pZi+Y2SYz2xg8V7B9n9aBX4YN2u4Abjjluc8DP3f3ZcDPg8elZBD4rLsvBy4F\nPhH8Py71/e4DrnX3C4GLgBvM7FJKf7+H3AK8Muxxuew3wNvc/aJh0zELtu/TOvApswZt7r4OOHzK\n0+8GvhPc/w7wnkktKmLu/oa7PxPc7yAfAnMp/f12d+8MHiaDm1Pi+w1gZvOAdwLfHPZ0ye/3GAq2\n79M98NWgDZrd/Y3g/n7g7Ndxm+LMrAVYCTxJGex3MKyxCWgFHnT3sthv4KvAHwHDVw4vh/2G/Jf6\nf5rZ02a2JniuYPuuNW1LiLu7mZXktCszqwH+FbjV3duHLzJdqvvt7lngIjObAdxrZitO+X3J7beZ\n3Qi0uvvTZnbNSK8pxf0e5kp332dmTcCDZrZ5+C8nuu/T/Qg/VIO2EnfAzOYABD9bi1xPwZlZknzY\n3+Xu/xYh/A4nAAADHElEQVQ8XfL7PcTdjwIPkT9/U+r7fQXwLjPbSX6I9lozu5PS328A3H1f8LMV\nuJf8sHXB9n26B/5TwDIzW2RmFcAHgfuKXNNkuw/4aHD/o8CPilhLwVn+UP5bwCvu/pVhvyr1/W4M\njuwxszRwPbCZEt9vd/8Td5/n7i3k/z3/wt1vosT3G8DMqs2sdug+8HbgRQq479P+wiszewf5Mb+h\nBm1/WeSSImNmdwPXkO+gdwD4U+DfgR8AC8h3Gv0tdz/1xO60ZWZXAo8CL3BiTPcL5MfxS3m/LyB/\ngi5O/sDsB+7+Z2bWQAnv93DBkM4fuvuN5bDfZraY/FE95Ifbv+fuf1nIfZ/2gS8iIuFM9yEdEREJ\nSYEvIlImFPgiImVCgS8iUiYU+CIiZUKBLyXJzDqDny1m9tsF/uwvnPL4sUJ+vkhUFPhS6lqAMwp8\nMxuv5chJge/ul59hTSJFocCXUvdXwFuD/uKfDhqS/W8ze8rMnjez34f8RT5m9qiZ3Qe8HDz370ET\nq5eGGlmZ2V8B6eDz7gqeG/prwoLPfjHoaf6BYZ/9sJndY2abzewuG94MSGSSqHmalLrPE1ytCRAE\n9zF3v8TMKoH1ZvYfwWsvBla4+47g8e+6++GgtcFTZvav7v55M/uku180wrZ+g3zv+gvJXw39lJmt\nC363Engz8DqwnnzPmF8WfndFRqcjfCk3bwc+ErQdfhJoAJYFv9swLOwB/oeZPQc8Qb5J3zLGdiVw\nt7tn3f0A8AhwybDP3uvuOWAT+aEmkUmlI3wpNwZ8yt1/dtKT+b4tXac8vg64zN27zexhIDWB7fYN\nu59F//akCHSEL6WuA6gd9vhnwH8PWi5jZucGnQlPVQccCcL+fPLLKw4ZGHr/KR4FPhCcJ2gErgI2\nFGQvRApARxlS6p4HssHQzB3A35IfTnkmOHHaxshLxj0A/IGZvQJsIT+sM2Qt8LyZPePuHx72/L3A\nZcBz5Fcu+iN33x98YYgUnbplioiUCQ3piIiUCQW+iEiZUOCLiJQJBb6ISJlQ4IuIlAkFvohImVDg\ni4iUCQW+iEiZ+P+MMgWaL+MGIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26e78c1110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numpy.arange(50), numpy.multiply(numpy.mean(response_time_dual, axis=0), 1000))\n",
    "plt.ylabel(\"Mean Response Time\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome devaluation for overtraining. (Change = True, change_at = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_dual = list()\n",
    "reward_dual = list()\n",
    "steps_dual = list()\n",
    "time_per_reward_dual = list()\n",
    "first_action_dual = list()\n",
    "change_at = 30\n",
    "iterations = 50\n",
    "change = True\n",
    "trials = 10\n",
    "for i in range(trials):\n",
    "    environment = numpy.zeros((7, 7))\n",
    "    trans_prob = 0.7\n",
    "    environment[6, 6] = 10\n",
    "    #environment[8, 8] = -10\n",
    "    environment[0, 0] = -10\n",
    "    mb_internal_environment = numpy.zeros((7, 7))\n",
    "    #mb_internal_environment[6, 6] = 10\n",
    "    start_time = time.time()\n",
    "    dual_result = dual(iterations, mb_internal_environment, change, change_at)\n",
    "    reward_dual.append(dual_result[0])\n",
    "    steps_dual.append(dual_result[1])\n",
    "    times_dual.append(time.time() - start_time)\n",
    "    time_per_reward_dual.append(dual_result[3])\n",
    "    first_action_dual.append(dual_result[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 8]\n",
      "0.745\n"
     ]
    }
   ],
   "source": [
    "#print collections.Counter(first_action_dual)\n",
    "#print first_action_dual\n",
    "stay_percentage_overtrain = list()\n",
    "print collections.Counter(tuple(i) for i in first_action_dual[0][change_at:]).values()\n",
    "for i in range(trials):\n",
    "    stay_percentage_overtrain.append(max(collections.Counter(tuple(i) for i in first_action_dual[i][change_at:]).values())/float(iterations-change_at))\n",
    "print numpy.mean(stay_percentage_overtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome Devaluation for moderately trained. (Change == True, change_at = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times_dual = list()\n",
    "reward_dual = list()\n",
    "steps_dual = list()\n",
    "time_per_reward_dual = list()\n",
    "first_action_dual = list()\n",
    "change_at = 10\n",
    "iterations = 50\n",
    "change = True\n",
    "trials = 10\n",
    "for i in range(trials):\n",
    "    environment = numpy.zeros((7, 7))\n",
    "    trans_prob = 0.7\n",
    "    environment[6, 6] = 10\n",
    "    #environment[8, 8] = -10\n",
    "    environment[0, 0] = -10\n",
    "    mb_internal_environment = numpy.zeros((7, 7))\n",
    "    #mb_internal_environment[6, 6] = 10\n",
    "    start_time = time.time()\n",
    "    dual_result = dual(iterations, mb_internal_environment, change, change_at)\n",
    "    reward_dual.append(dual_result[0])\n",
    "    steps_dual.append(dual_result[1])\n",
    "    times_dual.append(time.time() - start_time)\n",
    "    time_per_reward_dual.append(dual_result[3])\n",
    "    first_action_dual.append(dual_result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 29]\n",
      "0.275\n"
     ]
    }
   ],
   "source": [
    "#print collections.Counter(first_action_dual)\n",
    "stay_percentage_moderatelytrained = list()\n",
    "print collections.Counter(tuple(i) for i in first_action_dual[0][change_at:]).values()\n",
    "for i in range(trials):\n",
    "    stay_percentage_moderatelytrained.append((1 - max(collections.Counter(tuple(i) for i in first_action_dual[i][change_at:]).values())/float(iterations-change_at)))\n",
    "print numpy.mean(stay_percentage_moderatelytrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5649ecf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stay_percentage_labels = [\"Overtrained\", \"Moderately trained\"]\n",
    "plt.bar(numpy.arange(2), (numpy.mean(stay_percentage_overtrain), numpy.mean(stay_percentage_moderatelytrained)), color = 'b')\n",
    "plt.xticks(numpy.arange(2), stay_percentage_labels)\n",
    "plt.ylabel(\"First Action Stay Percentage\")\n",
    "plt.title(\"Outcome Devaluation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times_mb = list()\n",
    "reward_mb = list()\n",
    "steps_mb = list()\n",
    "time_per_reward_mb = list()\n",
    "for i in range(10):\n",
    "    mb_internal_environment = numpy.zeros((7, 7))\n",
    "    #mb_internal_environment[6, 6] = 10\n",
    "    start_time = time.time()\n",
    "    mb_result = mb(30, mb_internal_environment)\n",
    "    reward_mb.append(mb_result[0])\n",
    "    steps_mb.append(mb_result[1])\n",
    "    times_mb.append(time.time() - start_time)\n",
    "    time_per_reward_mb.append(mb_result[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times_mf = list()\n",
    "reward_mf = list()\n",
    "steps_mf = list()\n",
    "time_per_reward_mf = list()\n",
    "for i in range(10):\n",
    "    mb_internal_environment = numpy.zeros((7, 7))\n",
    "    #mb_internal_environment[6, 6] = 10\n",
    "    start_time = time.time()\n",
    "    mf_result = mf(30, mb_internal_environment)\n",
    "    reward_mf.append(mf_result[0])\n",
    "    steps_mf.append(mf_result[1])\n",
    "    times_mf.append(time.time() - start_time)\n",
    "    time_per_reward_mf.append(mf_result[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plotting time to complete one trial -- one walk through the environment. The walk completes on reward. \n",
    "The plot shows the dual process approaches TD in completing the walk through the environment -- showing goal directed behavior converted to habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeperrewardmb_plot = plt.plot(numpy.arange(0, 30), numpy.mean(numpy.array(time_per_reward_mb), axis=0), color = 'b', label = 'MB')\n",
    "timeperrewardmf_plot = plt.plot(numpy.arange(0, 30), numpy.mean(numpy.array(time_per_reward_mf), axis=0), color = 'r', label = 'MF')\n",
    "timeperrewarddual_plot = plt.plot(numpy.arange(0, 30), numpy.mean(numpy.array(time_per_reward_dual), axis=0), color = 'g', label = 'Dual')\n",
    "plt.legend()\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Time to reach goal')\n",
    "\n",
    "#plt.xticks(numpy.arange(3), ('mb', 'dual', 'mf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward_mean_dual = numpy.mean(numpy.array(reward_dual))\n",
    "reward_mean_mb = numpy.mean(numpy.array(reward_mb))\n",
    "reward_mean_mf = numpy.mean(numpy.array(reward_mf))\n",
    "times_mean_dual = numpy.mean(numpy.array(times_dual))\n",
    "times_mean_mb = numpy.mean(numpy.array(times_mb))\n",
    "times_mean_mf = numpy.mean(numpy.array(times_mf))\n",
    "steps_mean_dual = numpy.mean(steps_dual)\n",
    "steps_mean_mb = numpy.mean(steps_mb)\n",
    "steps_mean_mf = numpy.mean(steps_mf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print steps_mean_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stepsmf_plot, = plt.plot(numpy.arange(0, 30), numpy.mean(numpy.array(steps_mf), axis=0), color = 'r', label = 'MF')\n",
    "stepsdual_plot, = plt.plot(numpy.arange(0, 30), numpy.mean(numpy.array(steps_dual), axis=0), color = 'g', label = 'Dual')\n",
    "stepsmb_plot, = plt.plot(numpy.arange(0, 30), numpy.mean(numpy.array(steps_mb), axis=0), color = 'b', label = 'MB')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rewards = numpy.array([reward_mean_mb, reward_mean_dual, reward_mean_mf])\n",
    "#yerror = numpy.array(reward_errors)\n",
    "print (rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward_plot, = plt.plot(numpy.arange(0, 3), rewards)\n",
    "plt.xticks(numpy.arange(3), ('mb', 'dual', 'mf'))\n",
    "plt.xlim(xmin = -1, xmax = 4)\n",
    "#plt.ylim(ymin = 4.5, ymax = 5.5)\n",
    "plt.xlabel('RL methods')\n",
    "plt.ylabel(\"Rewards\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = numpy.array([times_mean_mb, times_mean_dual, times_mean_mf])\n",
    "print (times)\n",
    "plt.bar(numpy.arange(3), times, align='center')\n",
    "plt.xticks(numpy.arange(3), ('mb', 'dual', 'mf'))\n",
    "plt.xlim(xmin = -1, xmax = 4)\n",
    "#plt.ylim(ymin = -1, ymax = 10)\n",
    "plt.xlabel('RL methods')\n",
    "plt.ylabel(\"Time (in secs)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = numpy.array([steps_mean_mb, steps_mean_dual, steps_mean_mf])\n",
    "print (steps)\n",
    "plt.bar(numpy.arange(3), steps, align='center')\n",
    "plt.xticks(numpy.arange(3), ('mb', 'dual', 'mf'))\n",
    "plt.xlim(xmin = -1, xmax = 3)\n",
    "#plt.ylim(ymin = 350, ymax = 400)\n",
    "plt.xlabel('RL methods')\n",
    "plt.ylabel(\"Stpes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
